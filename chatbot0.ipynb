{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNgD0cqUU3gEI8u8XucQAYT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aatika1/openai-API/blob/main/chatbot0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture --no-stderr\n",
        "%pip install -U langgraph langsmith langchain_google_genai"
      ],
      "metadata": {
        "id": "D6vJ5nJvGR6H"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = userdata.get('LANGCHAIN_API_KEY')\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"quickstart\"\n",
        "\n",
        "gemini_api_key = userdata.get('GEMINI_API_KEY')"
      ],
      "metadata": {
        "id": "ZHLQ2jVsGVLF"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-1.5-flash\",\n",
        "    max_retries=2,\n",
        "    api_key=gemini_api_key\n",
        ")\n",
        "\n",
        "llm.invoke(\"greet me\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmGkWBNCGeX4",
        "outputId": "0147be71-9ada-4e39-bced-64789d1d48a3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Hello there! How can I help you today? \\n', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-3a17ff43-0d49-4323-b571-31591c0c1cb9-0', usage_metadata={'input_tokens': 3, 'output_tokens': 11, 'total_tokens': 14, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Annotated\n",
        "\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "\n",
        "class State(TypedDict):\n",
        "    # Messages have the type \"list\". The `add_messages` function\n",
        "    # in the annotation defines how this state key should be updated\n",
        "    # (in this case, it appends messages to the list, rather than overwriting them)\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "\n",
        "graph_builder = StateGraph(State)"
      ],
      "metadata": {
        "id": "vElWTet3GwuY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # # Example usage of add_messages\n",
        "new_messages_1 = [{\"role\": \"user\", \"content\": \"Hello\"}]\n",
        "new_messages_2 = [{\"role\": \"ai\", \"content\": \"Hi there!\"}]\n",
        "\n",
        "messages = add_messages(new_messages_1, new_messages_2)\n",
        "\n",
        "\n",
        "print(\"Updated State 1:\", messages)\n",
        "\n",
        "# from typing import Annotated\n",
        "# from typing_extensions import TypedDict\n",
        "# from langgraph.graph import StateGraph\n",
        "\n",
        "# class State(TypedDict):\n",
        "#     messages: Annotated[list, add_messages]\n",
        "\n",
        "# builder = StateGraph(State)\n",
        "# builder.add_node(\"chatbot\", lambda state: {\"messages\": [(\"assistant\", \"Hello\")]})\n",
        "# builder.set_entry_point(\"chatbot\")\n",
        "# builder.set_finish_point(\"chatbot\")\n",
        "# graph = builder.compile()\n",
        "# graph.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"Hello\"}]})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEsbAIg_G1Dr",
        "outputId": "3aace5e7-52fa-4148-c10a-878ec66ce4ca"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated State 1: [HumanMessage(content='Hello', additional_kwargs={}, response_metadata={}, id='390565a0-21a6-409e-8c86-8de04068cde9'), AIMessage(content='Hi there!', additional_kwargs={}, response_metadata={}, id='546d49ca-6837-4844-8b12-338f1c7c4698')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def chatbot(state: State):\n",
        "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
        "\n",
        "\n",
        "# The first argument is the unique node name\n",
        "# The second argument is the function or object that will be called whenever\n",
        "# the node is used.\n",
        "graph_builder.add_node(\"chatbot\", chatbot)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eAzarQQWG9af",
        "outputId": "197813d8-90e9-44c6-c4d2-bd7e3bcbac4f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7c61ce73c850>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "graph_builder.add_edge(START,\"chatbot\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07F7nV8THCPA",
        "outputId": "d1074c22-0530-411a-c18d-b52cf29ac8c6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7c61ce73c850>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "graph_builder.add_edge(\"chatbot\",END)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5KHr4qqHLgD",
        "outputId": "235357ac-8aa3-4701-c3ae-1500ff36ac0a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7c61ce73c850>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "graph=graph_builder.compile()"
      ],
      "metadata": {
        "id": "NSoaNXcmHOiD"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for bussines in graph.stream({\"messages\": [\"user\",\"Hello I am abuzar\"]}):\n",
        "  print(\"bussines:\", list(bussines.values())[0][\"messages\"][-1].content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fBC5s5EBHajP",
        "outputId": "b9e60312-accd-48ed-9331-e4b66ee99833"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bussines: Hello Abuzar! Nice to meet you.  What can I do for you today? \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def graph_updates(user_input:str):\n",
        "  for bussines in graph.stream({\"messages\": [(\"user\",user_input)]}):\n",
        "    for value in bussines.values():\n",
        "        print(\"Assistant: \", value[\"messages\"][-1].content)\n",
        "\n",
        "while True:\n",
        "  try:\n",
        "    user_input=input(\"user: \")\n",
        "    if user_input.lower() in [\"exit\",\"quit\",\"bye\"]:\n",
        "      print(\"Nice to meet you\")\n",
        "      break\n",
        "\n",
        "    graph_updates(user_input)\n",
        "  except:\n",
        "    #fallback if input() is not available\n",
        "    user_input=\"what do you know about langGraph\"\n",
        "    print(\"user\" + user_input)\n",
        "    graph_updates(user_input)\n",
        "    break\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKMROY_JH4qo",
        "outputId": "84d7a861-3ea9-4874-994e-c6335e4de156"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "user: hi\n",
            "Assistant:  Hi there! How can I help you today? \n",
            "\n",
            "user: exit\n",
            "Nice to meet you\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture --no-stderr\n",
        "%pip install -U tavily-python langchain_community"
      ],
      "metadata": {
        "id": "1r4Qf-RzBtT_"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"TAVILY_API_KEY\"] = userdata.get(\"TAVILY_API_KEY\")"
      ],
      "metadata": {
        "id": "RE_OpaJWBzJM"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "\n",
        "search_tool = TavilySearchResults(max_results=2)\n",
        "\n"
      ],
      "metadata": {
        "id": "7TckG8ckB7Mf"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search_tool.invoke(\"current cm of sindh pakistan\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_a5uF8nXCDLn",
        "outputId": "cd7f3688-bf27-4fb3-d538-5eac553552b1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'url': 'https://en.wikipedia.org/wiki/Chief_Minister_of_Sindh',\n",
              "  'content': 'cm.sindh.gov.pk. The chief minister of Sindh (Sindhi: ÙˆØ²ÙŠØ±Ø§Ø¹Ù„ÙŠ, Urdu: ÙˆØ²ÛŒØ± Ø§Ø¹Ù„Ù‰Ù° â€” WazÄ«r-e AÊ¿lÃ¡), is the elected head of government of Sindh and serves alongside the Chief Secretary. Syed Murad Ali Shah is the current Chief Minister of Sindh, serving as a Government of Sindh since 26 February 2024. The chief minister is'},\n",
              " {'url': 'https://www.nation.com.pk/27-Feb-2024/profile-of-newly-elected-sindh-cm-murad-ali-shah',\n",
              "  'content': \"KARACHI - Newly elected Sindh Chief Min\\xadister (CM) Sayed Murad Ali Shah belongs to a political family of Sindh's Jamshoro district. He was born on November 8, 1962 at Karachi. His father Syed Abdullah Shah was also served as chief minister of Sindh province from October 21, 1993 to November 6, 1996, during the Pakistan People's Party's\"}]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tools=[search_tool]"
      ],
      "metadata": {
        "id": "6sttz5zICMa-"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Annotated\n",
        "\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "\n",
        "class State(TypedDict):\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "\n",
        "graph_builder = StateGraph(State)\n",
        "\n",
        "\n",
        "# Modification: tell the LLM which tools it can call\n",
        "llm_with_tools = llm.bind_tools(tools)\n",
        "\n",
        "\n",
        "def chatbot(state: State):\n",
        "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
        "\n",
        "\n",
        "graph_builder.add_node(\"chatbot\", chatbot)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rcac4yZGDInT",
        "outputId": "20480e2e-78db-4ca1-c579-dcd1622b4ea7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7c61cc54ffd0>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bS7z-SqWFW7h",
        "outputId": "df1cfe38-15a4-48c9-df6a-cfe765acae1f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatGoogleGenerativeAI(model='models/gemini-1.5-flash', google_api_key=SecretStr('**********'), max_retries=2, client=<google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x7c61cf0563b0>, default_metadata=())"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm_with_tools"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1-BApVGFYnR",
        "outputId": "60bde10c-e361-408a-f93b-8a1ed5342c74"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RunnableBinding(bound=ChatGoogleGenerativeAI(model='models/gemini-1.5-flash', google_api_key=SecretStr('**********'), max_retries=2, client=<google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x7c61cf0563b0>, default_metadata=()), kwargs={'tools': [{'type': 'function', 'function': {'name': 'tavily_search_results_json', 'description': 'A search engine optimized for comprehensive, accurate, and trusted results. Useful for when you need to answer questions about current events. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}]}, config={}, config_factories=[])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm_with_tools.invoke(\"say welcome to zahreen\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCISadn7FbKa",
        "outputId": "ed627452-a8cd-4ded-d8f3-609eb57619e6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Welcome, Zahreen! ðŸ‘‹  ðŸ˜Š \\n', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-cf75767f-3d5c-4dca-97f5-a008d71fbb21-0', usage_metadata={'input_tokens': 79, 'output_tokens': 8, 'total_tokens': 87, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tools_by_name = {tool.name: tool for tool in tools}\n",
        "print(type(tools_by_name))\n",
        "print(tools_by_name)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kon4t_G8FoNd",
        "outputId": "a23c2cd1-b4d9-4fcb-b9d4-a5b96b6a66c1"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'dict'>\n",
            "{'tavily_search_results_json': TavilySearchResults(max_results=2, api_wrapper=TavilySearchAPIWrapper(tavily_api_key=SecretStr('**********')))}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tools_by_name[\"tavily_search_results_json\"]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RRKfoJXCHcFk",
        "outputId": "6c80b02e-13d4-45c2-dcfe-c80d266996b3"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TavilySearchResults(max_results=2, api_wrapper=TavilySearchAPIWrapper(tavily_api_key=SecretStr('**********')))"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Annotated\n",
        "\n",
        "\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langchain_core.messages import BaseMessage\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "from langgraph.graph import StateGraph\n",
        "from langgraph.graph.message import add_messages\n",
        "from langgraph.prebuilt import ToolNode, tools_condition\n",
        "\n",
        "\n",
        "class State(TypedDict):\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "\n",
        "graph_builder = StateGraph(State)\n",
        "\n",
        "\n",
        "tool = TavilySearchResults(max_results=2)\n",
        "tools = [tool]\n",
        "\n",
        "llm_with_tools = llm.bind_tools(tools)\n",
        "\n",
        "\n",
        "def chatbot(state: State):\n",
        "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
        "\n",
        "\n",
        "graph_builder.add_node(\"chatbot\", chatbot)\n",
        "\n",
        "tool_node = ToolNode(tools=[tool])\n",
        "graph_builder.add_node(\"tools\", tool_node)\n",
        "\n",
        "graph_builder.add_conditional_edges(\n",
        "    \"chatbot\",\n",
        "    tools_condition,\n",
        ")\n",
        "# Any time a tool is called, we return to the chatbot to decide the next step\n",
        "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
        "graph_builder.set_entry_point(\"chatbot\")\n",
        "graph = graph_builder.compile()"
      ],
      "metadata": {
        "id": "j-qePeT78zc7"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    try:\n",
        "        user_input = input(\"User: \")\n",
        "        if user_input.lower() in [\"quit\", \"exit\", \"bye\"]:\n",
        "            print(\"Nice to meet yoy!\")\n",
        "            break\n",
        "\n",
        "        graph_updates(user_input)\n",
        "    except:\n",
        "        # fallback if input() is not available\n",
        "        user_input = \"What do you know about LangGraph?\"\n",
        "        print(\"User: \" + user_input)\n",
        "        graph_updates(user_input)\n",
        "        break"
      ],
      "metadata": {
        "id": "T4Ojong0-0WH",
        "outputId": "45def899-93d7-473f-d84b-e9e9df1fc036",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User: what is current weather of ratodero\n",
            "Assistant:  \n",
            "Assistant:  [{\"url\": \"https://www.weatherapi.com/\", \"content\": \"{'location': {'name': 'Ratodero', 'region': 'Sindh', 'country': 'Pakistan', 'lat': 27.8, 'lon': 68.3, 'tz_id': 'Asia/Karachi', 'localtime_epoch': 1731425386, 'localtime': '2024-11-12 20:29'}, 'current': {'last_updated_epoch': 1731424500, 'last_updated': '2024-11-12 20:15', 'temp_c': 28.1, 'temp_f': 82.6, 'is_day': 0, 'condition': {'text': 'Clear', 'icon': '//cdn.weatherapi.com/weather/64x64/night/113.png', 'code': 1000}, 'wind_mph': 4.9, 'wind_kph': 7.9, 'wind_degree': 318, 'wind_dir': 'NW', 'pressure_mb': 1011.0, 'pressure_in': 29.86, 'precip_mm': 0.0, 'precip_in': 0.0, 'humidity': 24, 'cloud': 2, 'feelslike_c': 26.5, 'feelslike_f': 79.6, 'windchill_c': 28.1, 'windchill_f': 82.6, 'heatindex_c': 26.5, 'heatindex_f': 79.6, 'dewpoint_c': 5.5, 'dewpoint_f': 41.8, 'vis_km': 10.0, 'vis_miles': 6.0, 'uv': 0.0, 'gust_mph': 10.3, 'gust_kph': 16.6}}\"}, {\"url\": \"https://www.weather-forecast.com/locations/Ratodero/forecasts/latest\", \"content\": \"Local time in Ratodero is 8:06:40 AM PKT. Mostly dry. Warm (max 38Â°C on Fri afternoon, min 28Â°C on Wed night). Wind will be generally light. Mostly dry. Warm (max 39Â°C on Sun afternoon, min 27Â°C on Mon night). Wind will be generally light. Mostly dry. Warm (max 39Â°C on Thu afternoon, min 27Â°C on Tue night).\"}]\n",
            "Assistant:  The current weather in Ratodero, Pakistan is Clear with a temperature of 28.1 degrees Celsius. The wind is blowing from the northwest at 7.9 kilometers per hour. The humidity is 24%. \n",
            "\n",
            "User: exit\n",
            "Nice to meet yoy!\n"
          ]
        }
      ]
    }
  ]
}